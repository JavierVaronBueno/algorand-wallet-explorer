{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EnhancedWhaleMetricsTransformer: Análisis Avanzado de Métricas de Whales\n",
    "\n",
    "Componentes clave:\n",
    "\n",
    "1. Transformación de Datos:\n",
    "- Procesa múltiples CSVs de wallets\n",
    "- Normaliza métricas usando StandardScaler\n",
    "- Genera series temporales horarias\n",
    "\n",
    "2. Métricas Calculadas:\n",
    "- Balance total y promedio\n",
    "- Volumen 24h\n",
    "- Flujo neto\n",
    "- Whales activas\n",
    "- Tamaño promedio de transacciones\n",
    "- Índice de concentración (Herfindahl-Hirschman)\n",
    "\n",
    "3. Características Técnicas:\n",
    "- Ventana móvil de 24h\n",
    "- Normalización de features\n",
    "- Forward fill para datos faltantes\n",
    "- Manejo de timestamps\n",
    "- Agregación por hora\n",
    "\n",
    "Innovación principal: Calcula índice de concentración para medir distribución del poder económico entre whales.\n",
    "\n",
    "Uso: Análisis de comportamiento colectivo de whales y su impacto en el mercado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class EnhancedWhaleMetricsTransformer:\n",
    "    def __init__(self, start_date: str = '2023-01-01'):\n",
    "        \"\"\"\n",
    "        Initialize the transformer with a start date for historical data\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date in 'YYYY-MM-DD' format\n",
    "        \"\"\"\n",
    "        self.start_date = pd.Timestamp(start_date)\n",
    "        self.end_date = pd.Timestamp.now()\n",
    "        \n",
    "    def _process_wallet_file(self, file_path: str) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process individual wallet CSV file\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "        df['monto'] = pd.to_numeric(df['monto'], errors='coerce')\n",
    "        return df\n",
    "    \n",
    "    def _calculate_hourly_metrics(self, wallet_dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Calculate hourly metrics for all wallets\n",
    "        \"\"\"\n",
    "        # Create date range for all hours\n",
    "        date_range = pd.date_range(start=self.start_date, end=self.end_date, freq='h')\n",
    "        metrics_list = []\n",
    "        \n",
    "        for timestamp in date_range:\n",
    "            window_start = timestamp - pd.Timedelta(hours=24)\n",
    "            \n",
    "            # Initialize metrics for this hour\n",
    "            hour_metrics = {\n",
    "                'timestamp': timestamp,\n",
    "                'whale_total_balance': 0,\n",
    "                'whale_avg_balance': 0,\n",
    "                'whale_balance_std': 0,\n",
    "                'whale_total_volume_24h': 0,\n",
    "                'whale_net_flow': 0,\n",
    "                'active_whales': 0,\n",
    "                'whale_avg_tx_size': 0,\n",
    "                'whale_concentration': 0\n",
    "            }\n",
    "            \n",
    "            wallet_balances = []\n",
    "            tx_sizes = []\n",
    "            active_wallets = set()\n",
    "            \n",
    "            for wallet_df in wallet_dfs:\n",
    "                # Get transactions in the last 24 hours for this wallet\n",
    "                mask_24h = (wallet_df['fecha'] > window_start) & (wallet_df['fecha'] <= timestamp)\n",
    "                recent_txs = wallet_df[mask_24h]\n",
    "                \n",
    "                if len(recent_txs) > 0:\n",
    "                    # Calculate wallet metrics\n",
    "                    received = recent_txs[recent_txs['tipo'] == 'Recibido']['monto'].sum()\n",
    "                    sent = recent_txs[recent_txs['tipo'] == 'Enviado']['monto'].sum()\n",
    "                    balance = received - sent\n",
    "                    \n",
    "                    wallet_balances.append(balance)\n",
    "                    tx_sizes.extend(recent_txs['monto'].tolist())\n",
    "                    \n",
    "                    if len(recent_txs) > 0:\n",
    "                        active_wallets.add(wallet_df['remitente'].iloc[0])\n",
    "            \n",
    "            # Calculate aggregated metrics\n",
    "            if wallet_balances:\n",
    "                hour_metrics.update({\n",
    "                    'whale_total_balance': sum(wallet_balances),\n",
    "                    'whale_avg_balance': np.mean(wallet_balances),\n",
    "                    'whale_balance_std': np.std(wallet_balances) if len(wallet_balances) > 1 else 0,\n",
    "                    'whale_total_volume_24h': sum(abs(x) for x in tx_sizes),\n",
    "                    'whale_net_flow': sum(wallet_balances),\n",
    "                    'active_whales': len(active_wallets),\n",
    "                    'whale_avg_tx_size': np.mean(tx_sizes) if tx_sizes else 0,\n",
    "                    'whale_concentration': self._calculate_concentration(wallet_balances)\n",
    "                })\n",
    "            \n",
    "            metrics_list.append(hour_metrics)\n",
    "        \n",
    "        return pd.DataFrame(metrics_list)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _calculate_concentration(balances: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Herfindahl-Hirschman concentration index\n",
    "        \"\"\"\n",
    "        if not balances or sum(balances) == 0:\n",
    "            return 0\n",
    "            \n",
    "        total = sum(abs(b) for b in balances)\n",
    "        market_shares = [abs(b)/total for b in balances]\n",
    "        return sum(share * share for share in market_shares)\n",
    "    \n",
    "    def transform(self, csv_files: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform wallet CSVs into consolidated metrics DataFrame\n",
    "        \n",
    "        Args:\n",
    "            csv_files: List of paths to wallet CSV files\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with hourly metrics\n",
    "        \"\"\"\n",
    "        # Process all wallet files\n",
    "        wallet_dfs = [self._process_wallet_file(f) for f in csv_files]\n",
    "        \n",
    "        # Calculate hourly metrics\n",
    "        metrics_df = self._calculate_hourly_metrics(wallet_dfs)\n",
    "        \n",
    "        # Normalize features\n",
    "        scaler = StandardScaler()\n",
    "        columns_to_normalize = [col for col in metrics_df.columns if col != 'timestamp']\n",
    "        metrics_df[columns_to_normalize] = scaler.fit_transform(metrics_df[columns_to_normalize])\n",
    "        \n",
    "        # Set timestamp as index\n",
    "        metrics_df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        # Forward fill missing values\n",
    "        metrics_df.fillna(method='ffill', inplace=True)\n",
    "        \n",
    "        return metrics_df\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # List of CSV files\n",
    "    csv_files = [\n",
    "        'C:/Users/Nabucodonosor/Documents/BITLINK/Repositorios/explorer-wallets/algorand_reports/wallet_transactions_BX7UST4VVWQQPPAVPMPFW76QRKXRLQ3UVYABWBTHOAX2AN5Q5OGW2X55AQ_20241227_185401.csv',\n",
    "        'C:/Users/Nabucodonosor/Documents/BITLINK/Repositorios/explorer-wallets/algorand_reports/wallet_transactions_R7ALVPEQRGECJK33LANXMPENWYALTAZQTSGNCTEQPKBSBDI5KO252SAK64_20241227_185604.csv',\n",
    "        'C:/Users/Nabucodonosor/Documents/BITLINK/Repositorios/explorer-wallets/algorand_reports/wallet_transactions_UI6AGNWYGQD6HNQVEZ5ZTAQR27FHZ45VMLTS7LTSF2IZGAJMOIF4V4EEVU_20241227_184610.csv'\n",
    "    ]\n",
    "    \n",
    "    # Create transformer and process data\n",
    "    transformer = EnhancedWhaleMetricsTransformer(start_date='2023-01-01')\n",
    "    metrics_df = transformer.transform(csv_files)\n",
    "    \n",
    "    # Save to CSV\n",
    "    metrics_df.to_csv('whale_metrics_hourly.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
